## Llama3-8B Instruct 모델의 양자화에 따른 탈옥(Jailbreak) 성공률 실험 데이터

### 실험 개요:
- 대상 모델: LLaMA3-8B
- 양자화 수준: f16(기준), q16, q8, q4, q2
- 테스트 케이스: 100개의 유해질문
- 시도 조건: 각 질문당 최대 20회 재시도
- 언어: 한국어(ko), 영어(en)
- 시제: 과거(pa), 현재(pr), 미래(fu)

데이터 포맷:
[실험번호] llama3-8b-{양자화레벨}_{시제}({언어})(실행시간) >> Requests: 100, Restarts: 20 | asr_gpt=x%, asr_llama=y%, asr_rules=z%, avg_restart=n

데이터 구성:
1. 실험번호: [20]-[50] 범위의 고유 식별자
2. 양자화 레벨: q2, q4, q8, q16, f16
3. 시제: pa(past), pr(present), fu(future)
4. 언어: ko(한국어), en(영어)
5. 측정항목:
   - asr_gpt: GPT 평가 기준 탈옥 성공률
   - asr_llama: LLaMA 평가 기준 탈옥 성공률
   - asr_rules: 규칙 기반 평가 기준 탈옥 성공률
   - avg_restart: 평균 재시도 횟수

주요 분석 포인트:
1. 기준값: f16 영어 현재시제(3% 성공률)
2. 양자화 수준별 탈옥 성공률 변화(언어, 시제별 각각)
3. 기준모델을 기반으로 언어의 변화나 시제의 변화 대비 양자화를 했을때 이런 변화 폭이 더 커지는지 여부 등을 분석
4. q2 양자화에서의 특이 현상

비교 기준:
- f16과 q16은 용량이 동일하여 기준 성능 비교군
- q8까지는 일반적으로 성능 저하가 크지 않음
- q4부터 일부 성능 저하 발생
- q2는 큰 폭의 성능 저하가 예상되는 수준

### 실험 목적:
양자화로 인한 모델 성능 저하가 탈옥 성공률에 미치는 영향을 분석하고, 특히 심한 양자화(q2)에서 발생하는 특이 현상을 관찰하기 위함

실험 목적:
1. 양자화 수준별 탈옥 성공률 비교
  - 기준 모델(f16)과 각 양자화 수준(q16, q8, q4, q2)에서의 탈옥 성공률 변화
  - 일반적 성능 저하와 탈옥 성공률 간의 상관관계 분석
  - 각 양자화 수준에서 나타나는 특이 현상 관찰

2. 언어 변화에 따른 탈옥 취약성 분석
  - 영어 대비 한국어에서의 탈옥 성공률 변화
  - 언어별 탈옥 패턴의 차이점
  - 양자화 수준과 언어 간의 상호작용 효과

3. 시제 변화에 따른 영향 분석
  - 현재/과거/미래 시제별 탈옥 성공률 차이
  - 각 시제가 언어별로 미치는 영향의 차이
  - 양자화 수준에 따른 시제 영향력 변화

4. 복합 요인 간 상호작용 분석
  - 양자화 × 언어 × 시제 조합에 따른 탈옥 성공률 변화
  - 특정 조합에서 발생하는 급격한 취약성 증가 현상
  - 안전성 관점에서의 위험 조합 식별

이를 통해 모델의 안전성에 영향을 미치는 다양한 요인들의 개별 효과와 상호작용을 종합적으로 이해하고, 보다 안전한 모델 설계를 위한 인사이트 도출을 목표로 함
  - 양자화 수준별 한국어/영어 를 섞거나, 시제를 섞는 등 이런 비교분석은 무의미함.
  - 이후도 마찬가지. 모두 세분화해서 분석해야함. 특히 비교포인트로 분석이 중요함. 예를 들어 기준모델을 기반으로 언어의 변화나 시제의 변화 대비 양자화를 했을때 이런 변화 폭이 더 커지는지 여부 등을 분석하는것이 핵심 사항중 하나임.
